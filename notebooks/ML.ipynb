{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6b4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-12 22:11:01.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataEngineer.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/jax/NHA-112\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory (project root)\n",
    "project_root = os.path.abspath('..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from dataEngineer.pipeLine import *\n",
    "from dataEngineer.modeling.MLmodel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecb3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd731b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jax/NHA-112/data/raw/Clean_ready_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d714af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568427, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22714005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                Summary  \\\n",
       "0       5  good quality dog food   \n",
       "1       1      not as advertised   \n",
       "2       4    delight says it all   \n",
       "3       2         cough medicine   \n",
       "4       5            great taffy   \n",
       "\n",
       "                                                Text  \n",
       "0  i have bought several of the vitality canned d...  \n",
       "1  product arrived labeled as jumbo salted peanut...  \n",
       "2  this is a confection that has been around a fe...  \n",
       "3  if you are looking for the secret ingredient i...  \n",
       "4  great taffy at a great price  there was a wide...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8006c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 568427 rows.\n",
      "Size after removing empty rows: 568426 rows.\n",
      "Applying sklearn pipeline for text cleaning and lemmatization...\n",
      "Text cleaning and lemmatization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jax/NHA-112/dataEngineer/pipeLine.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"processed_text\"] = processed_text_series\n"
     ]
    }
   ],
   "source": [
    "data_pipeline = text_preprocessing_sklearn_pipeline(df=df, text_col='Text', rate_col='Rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8f8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- No model found. Training new SVM model from scratch. ---\n",
      "Initializing a new SGDClassifier with hinge loss (Linear SVM).\n",
      "Initial model training complete.\n",
      "\n",
      "Model Accuracy: 0.6869\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.46      0.50     10454\n",
      "           2       0.24      0.03      0.05      5949\n",
      "           3       0.39      0.12      0.18      8527\n",
      "           4       0.44      0.05      0.09     16131\n",
      "           5       0.71      0.98      0.83     72625\n",
      "\n",
      "    accuracy                           0.69    113686\n",
      "   macro avg       0.47      0.33      0.33    113686\n",
      "weighted avg       0.61      0.69      0.60    113686\n",
      "\n",
      "Model and vectorizer saved successfully to /home/jax/NHA-112/models/\n"
     ]
    }
   ],
   "source": [
    "logreg_classifier = TextClassifier(model_type='svm')\n",
    "logreg_classifier.train(data_pipeline,text_column='processed_text',label_column='Rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d89359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully from /home/jax/NHA-112/models/\n",
      "\n",
      "Prediction for 'service was fast and the food was absolutely delicious': 5-star\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\"service was fast and the food was absolutely delicious\"]\n",
    "predictions = logreg_classifier.predict(new_reviews)\n",
    "print(f\"\\nPrediction for '{new_reviews[0]}': {predictions[0]}-star\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf71935",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = TextClassifier(model_type='svm')\n",
    "svm_classifier.train(data_pipeline,text_column='processed_text',label_column='Rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57553556",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [\"service was fast and the food was absolutely delicious\"]\n",
    "predictions = svm_classifier.predict(new_reviews)\n",
    "print(f\"\\nPrediction for '{new_reviews[0]}': {predictions[0]}-star\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62649dc",
   "metadata": {},
   "source": [
    "# train on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd6ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('/home/jax/NHA-112/data/interim/Scraped_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42bede94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>blew my expectations away truly nextgen gaming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>good for nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>fantastic deal on fast delivery great price an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>excellent product just nice for one hands i ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>super duper i use thanks noon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                               Text\n",
       "0       5  blew my expectations away truly nextgen gaming...\n",
       "1       3                                   good for nothing\n",
       "2       5  fantastic deal on fast delivery great price an...\n",
       "3       5  excellent product just nice for one hands i ha...\n",
       "4       5                      super duper i use thanks noon"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 2895 rows.\n",
      "Size after removing empty rows: 2711 rows.\n",
      "Applying sklearn pipeline for text cleaning and lemmatization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning and lemmatization complete.\n"
     ]
    }
   ],
   "source": [
    "data_pipeline = text_preprocessing_sklearn_pipeline(df=new_df, text_col='Text', rate_col='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Found existing model. Performing incremental update. ---\n",
      "Model and vectorizer loaded successfully from /home/jax/NHA-112/models/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 899 features, but SGDClassifier is expecting 1000 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlogreg_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprocessed_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRating\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NHA-112/dataEngineer/modeling/MLmodel.py:94\u001b[39m, in \u001b[36mTextClassifier.train\u001b[39m\u001b[34m(self, df, text_column, label_column)\u001b[39m\n\u001b[32m     91\u001b[39m X_test_tfidf = \u001b[38;5;28mself\u001b[39m.vectorizer.transform(X_test)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Update the model with the new batch using partial_fit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel update complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m.evaluate(X_test_tfidf, y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NHA-112/myenv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NHA-112/myenv/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:875\u001b[39m, in \u001b[36mBaseSGDClassifier.partial_fit\u001b[39m\u001b[34m(self, X, y, classes, sample_weight)\u001b[39m\n\u001b[32m    862\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    863\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    864\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mclass_weight \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not supported for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    865\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpartial_fit. In order to use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m\u001b[33m weights,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    872\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparameter.\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.class_weight)\n\u001b[32m    873\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NHA-112/myenv/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:598\u001b[39m, in \u001b[36mBaseSGDClassifier._partial_fit\u001b[39m\u001b[34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_partial_fit\u001b[39m(\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    585\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    595\u001b[39m     intercept_init,\n\u001b[32m    596\u001b[39m ):\n\u001b[32m    597\u001b[39m     first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclasses_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m     n_samples, n_features = X.shape\n\u001b[32m    611\u001b[39m     _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NHA-112/myenv/lib/python3.12/site-packages/sklearn/utils/validation.py:2975\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2975\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NHA-112/myenv/lib/python3.12/site-packages/sklearn/utils/validation.py:2839\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2840\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2842\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 899 features, but SGDClassifier is expecting 1000 features as input."
     ]
    }
   ],
   "source": [
    "logreg_classifier.train(data_pipeline,text_column='processed_text',label_column='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d3579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
